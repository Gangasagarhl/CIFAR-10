# -*- coding: utf-8 -*-
"""CIFAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gugHyou8g-KFoCAHKrGq44PiKM8CxLdl
"""

# importing libraries needed
import os
import numpy as np
import pandas as pd
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Dropout,Flatten,Activation,GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping,TensorBoard
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import save_model

# mnist data loading
(x_train,y_train),(x_test,y_test) = cifar10.load_data()

# printing shape of the xtrain and y_train
x_train.shape,y_train.shape,x_test.shape,y_test.shape

dictionary={0 : 'airplane', 1:'automobile' ,2 : 'bird',  3:'cat',
 4:'deer',
 5:'dog ',
 6: 'frog',
 7: 'horse',
 8:'ship',
 9:'truck'}





# scaling x_train and x_test data
x_train = x_train/255 
x_test  = x_test /255

y_train = y_train.reshape(-1,)
y_test = y_test.reshape(-1,)
y_train.shape,y_test.shape

print("The value expected to be->",dictionary[y_train[1]])
plt.imshow(x_train[1])

"""airplane : 0
automobile : 1
bird : 2
cat : 3
deer : 4
dog : 5
frog : 6
horse : 7
ship : 8
truck : 9
"""

print("Y_train unique values: ",sorted(pd.Series(y_train).unique()),
      "\nY_train Number Unique values:",len(sorted(pd.Series(y_train).unique()))
     )

print("\n\nY_test unique values: ",sorted(pd.Series(y_test).unique()),
      "\nY_test Number Unique values:",len(sorted(pd.Series(y_test).unique()))
     )

y_train_cat = to_categorical(y_train,num_classes=10)
y_test_cat = to_categorical(y_test,num_classes=10)

#getting maximum and minimum values of x_train and x_test respectivley
x_train.max(),x_test.max(),x_train.min(),x_test.min()

# printing shape of the xtrain and y_train
x_train.shape,y_train.shape,x_test.shape,y_test.shape

x_train = x_train.reshape(-1,32,32,3)
x_test = x_test.reshape(-1,32,32,3)

print(y_train[1])
y_train_cat

#building a sequential model
model = Sequential()
    
model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(32,32,3)))    
model.add(Dropout(0.2))
    
model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))  
model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2))    
model.add(Dropout(0.5))
    
model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))    
model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))
model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))    
model.add(Dropout(0.5))    
    
model.add(Conv2D(192, (3, 3), padding = 'same'))
model.add(Activation('relu'))
model.add(Conv2D(192, (1, 1),padding='valid'))
model.add(Activation('relu'))
model.add(Conv2D(10, (1, 1), padding='valid'))

model.add(GlobalAveragePooling2D())
    
model.add(Activation('softmax'))


model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

es =  EarlyStopping(monitor='val_loss', patience=5, mode='min')

model.summary()

model.fit(x=x_train,y=y_train_cat,epochs=300,callbacks=[es],validation_data=(x_test,y_test_cat),batch_size=(64))

history = pd.DataFrame(model.history.history)
print(history)

model.evaluate(x_test,y_test_cat)

model.evaluate(x_train,y_train_cat)

predictions = model.predict_classes(x_test)

from sklearn.metrics import classification_report

print(classification_report(y_test,predictions))

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,predictions)
cm

import seaborn as sns
plt.figure(figsize=(12,6))
sns.heatmap(cm,annot=True)

###  Testing through images

def testing(num): 
  img=x_train[num].reshape(-1,32,32,3)
  prediction = model.predict_classes(img)
  print("Prediction: ", dictionary[prediction[0]])
  print("Original: ",dictionary[y_train[num]])
  
  plt.imshow(x_train[num])

testing(5)

help(save_model)

model.save("/content/drive/My Drive/Data sets/saved_models/cifar10_model.h5")
model.save_weights(("/content/drive/My Drive/Data sets/saved_models/cifar10_weight.h5"))

from google.colab import drive
drive.mount('/content/drive')